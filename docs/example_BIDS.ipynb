{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## ECoG Movement decoding example \n",
    "\n",
    "This example notebook uses openly accessible data from the publication *Electrocorticography is superior to subthalamic local field potentials for movement decoding in Parkinsonâ€™s disease* ([Merk et al. 2022](https://elifesciences.org/articles/75126)). The dataset is available [here](https://doi.org/10.7910/DVN/IO2FLM).\n",
    "\n",
    "For simplicity one example subject is automatically shipped within this repo at the *examples/data* folder, stored in [iEEG BIDS](https://www.nature.com/articles/s41597-019-0105-7) format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import py_neuromodulation as nm\n",
    "from py_neuromodulation import (\n",
    "    nm_analysis,\n",
    "    nm_decode,\n",
    "    nm_define_nmchannels,\n",
    "    nm_IO,\n",
    "    nm_plots,\n",
    "    nm_settings,\n",
    "    nm_stats\n",
    ")\n",
    "from sklearn import (\n",
    "    metrics,\n",
    "    model_selection,\n",
    ")\n",
    "\n",
    "import xgboost\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's read the example using [mne_bids](https://mne.tools/mne-bids/stable/index.html). The resulting raw object is of type [mne.RawArray](https://mne.tools/stable/generated/mne.io.RawArray.html). We can use the properties such as sampling frequency, channel names, channel types all from the mne array and create the *nm_channels* dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_NAME, PATH_RUN, PATH_BIDS, PATH_OUT, datatype = nm_IO.get_paths_example_data()\n",
    "\n",
    "(\n",
    "    raw,\n",
    "    data,\n",
    "    sfreq,\n",
    "    line_noise,\n",
    "    coord_list,\n",
    "    coord_names,\n",
    ") = nm_IO.read_BIDS_data(\n",
    "    PATH_RUN=PATH_RUN, BIDS_PATH=PATH_BIDS, datatype=datatype\n",
    ")\n",
    "\n",
    "nm_channels = nm_define_nmchannels.set_channels(\n",
    "    ch_names=raw.ch_names,\n",
    "    ch_types=raw.get_channel_types(),\n",
    "    reference=\"default\",\n",
    "    bads=raw.info[\"bads\"],\n",
    "    new_names=\"default\",\n",
    "    used_types=(\"ecog\", \"dbs\", \"seeg\"),\n",
    "    target_keywords=[\"MOV_RIGHT_CLEAN\",\"MOV_LEFT_CLEAN\"]\n",
    ")\n",
    "\n",
    "nm_channels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example contains the force grip movement traces, we'll use the *MOV_RIGHT_CLEAN* channel as a decoding target channel. Let's check some of the raw feature and time series traces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4), dpi=300)\n",
    "plt.subplot(121)\n",
    "plt.plot(raw.times, data[-2, :])\n",
    "plt.xlabel(\"Time [s]\")\n",
    "plt.ylabel(\"a.u.\")\n",
    "plt.title(\"Movement label\")\n",
    "plt.xlim(0, 20)\n",
    "\n",
    "plt.subplot(122)\n",
    "for idx, ch_name in enumerate(nm_channels.query(\"used == 1\").name):\n",
    "    plt.plot(raw.times, data[idx, :] + idx*300, label=ch_name)\n",
    "plt.legend(bbox_to_anchor=(1, 0.5), loc='center left')\n",
    "plt.title(\"ECoG + STN-LFP time series\")\n",
    "plt.xlabel(\"Time [s]\")\n",
    "plt.ylabel(\"Voltage a.u.\")\n",
    "plt.xlim(0, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = nm_settings.get_default_settings()\n",
    "settings = nm_settings.set_settings_fast_compute(settings)\n",
    "\n",
    "settings[\"features\"][\"fft\"] = True\n",
    "settings[\"features\"][\"bursts\"] = True\n",
    "settings[\"features\"][\"sharpwave_analysis\"] = True\n",
    "settings[\"features\"][\"coherence\"] = True\n",
    "settings[\"coherence\"][\"channels\"] = [\n",
    "    [\n",
    "        \"LFP_RIGHT_0\",\n",
    "        \"ECOG_RIGHT_0\"\n",
    "    ]\n",
    "]\n",
    "settings[\"coherence\"][\"frequency_bands\"] = [\n",
    "    \"high beta\",\n",
    "    \"low gamma\"\n",
    "]\n",
    "settings[\"sharpwave_analysis_settings\"][\"estimator\"][\"mean\"] = []\n",
    "for sw_feature in list(\n",
    "    settings[\"sharpwave_analysis_settings\"][\"sharpwave_features\"].keys()\n",
    "):\n",
    "    settings[\"sharpwave_analysis_settings\"][\"sharpwave_features\"][sw_feature] = True\n",
    "    settings[\"sharpwave_analysis_settings\"][\"estimator\"][\"mean\"].append(sw_feature)\n",
    "\n",
    "# For further notebook demonstration, we will enable here also the\n",
    "# grid point projection.\n",
    "settings[\"postprocessing\"][\"project_cortex\"] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = nm.Stream(\n",
    "    sfreq=sfreq,\n",
    "    nm_channels=nm_channels,\n",
    "    settings=settings,\n",
    "    line_noise=line_noise,\n",
    "    coord_list=coord_list,\n",
    "    coord_names=coord_names,\n",
    "    verbose=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream.run(\n",
    "    data=data[:, :int(sfreq*60)],\n",
    "    out_path_root=PATH_OUT,\n",
    "    folder_name=RUN_NAME,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Featue Analysis\n",
    "\n",
    "The obtained performances can now be read and visualized using the *nm_analysis.Featuer_Reader*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init analyzer\n",
    "feature_reader = nm_analysis.Feature_Reader(\n",
    "    feature_dir=PATH_OUT, feature_file=RUN_NAME,\n",
    ")\n",
    "feature_reader.label_name = \"MOV_LEFT_CLEAN\"\n",
    "feature_reader.label = feature_reader.feature_arr[\"MOV_LEFT_CLEAN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_reader.feature_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_reader._get_target_ch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_reader.plot_target_averaged_channel(\n",
    "    ch=\"ECOG_RIGHT_0\",\n",
    "    list_feature_keywords=None,\n",
    "    epoch_len=4,\n",
    "    threshold=0.5,\n",
    "    ytick_labelsize=7,\n",
    "    figsize_x=12,\n",
    "    figsize_y=12\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_reader.plot_all_features(\n",
    "    ytick_labelsize=3,\n",
    "    clim_low=-2,\n",
    "    clim_high=2,\n",
    "    ch_used=\"ECOG_RIGHT_0\",\n",
    "    time_limit_low_s=30,\n",
    "    time_limit_high_s=60,\n",
    "    normalize=True,\n",
    "    save=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nm_plots.plot_corr_matrix(\n",
    "    feature = feature_reader.feature_arr.filter(regex='ECOG_RIGHT_0'),\n",
    "    ch_name= 'ECOG_RIGHT_0-avgref',\n",
    "    feature_names=feature_reader.feature_arr.filter(regex='ECOG_RIGHT_0-avgref').columns,\n",
    "    feature_file=feature_reader.feature_file,\n",
    "    show_plot=True,\n",
    "    figsize=(15,15),\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoding\n",
    "\n",
    "The main focus of the py_neuromodulation pipeline is the feature estimation. Nevertheless, the user can also use the pipeline for Machine Learning decoding. It can be used for regression and classification problems, and also using unsupervised methods, such as PCA and CCA.\n",
    "\n",
    "Here we show an example using the XGBOOST Classifier. The labels used come from the continuous grip force movement target, namedd \"MOV_LEFT_CLEAN\".\n",
    "\n",
    "First we initialize the *nm_decode.Decoder* class, which the specified *validation method*, here being a simple 3-fold cross validation, the evaluation metric, the used machine learning model, and the used channels we want to evaluate performances for.\n",
    "\n",
    "There are are many more implemented methods, but we will here limit here to the ones presented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "model = xgboost.sklearn.XGBRegressor()\n",
    "\n",
    "feature_reader.decoder = nm_decode.Decoder(\n",
    "    features=feature_reader.feature_arr,\n",
    "    label=feature_reader.label,\n",
    "    label_name=feature_reader.label_name,\n",
    "    used_chs=feature_reader.used_chs,\n",
    "    model=model,\n",
    "    eval_method=metrics.r2_score,\n",
    "    cv_method=model_selection.KFold(n_splits=3, shuffle=True),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performances = feature_reader.run_ML_model(\n",
    "    estimate_channels=True,\n",
    "    estimate_gridpoints=False,\n",
    "    estimate_all_channels_combined=True,\n",
    "    save_results=True,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performances is a dictionary, that we will now transform into a dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_per = feature_reader.get_dataframe_performances(performances)\n",
    "\n",
    "df_per"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = nm_plots.plot_df_subjects(\n",
    "    df_per, x_col=\"sub\", y_col=\"performance_test\", hue=\"ch_type\",\n",
    "    PATH_SAVE=os.path.join(PATH_OUT, RUN_NAME, RUN_NAME + \"_decoding_performance.png\")\n",
    ")\n",
    "ax.set_ylabel(r\"$R^2$ Correlation\")\n",
    "ax.set_xlabel(\"Subject 000\")\n",
    "ax.set_title(\"Performance comparison Movement decoding\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pn_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "da3498e8c8bcf8ece4d21a71c36ae1583960c5d2df7433d3ba5f7196029a2574"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
